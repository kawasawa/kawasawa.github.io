# Generated by GitHub Copilot

import os
import re
from pathlib import Path
from typing import List, Tuple

from config import TextSearchConfig
from entities import KnowledgeEntity


class TextSearchEngine:
    """
    ワークスペース内のファイルを走査し、アノテーションコメントを抽出するテキスト検索エンジン
    コメントの抽出・フィルタリング・検索の責務を担当
    """

    def __init__(self, workspace_root: Path, annotation_tag: str):
        """
        テキスト検索エンジンの初期化
        Args:
            workspace_root (Path): ワークスペースのルートディレクトリ
            annotation_tag (str): 抽出対象のアノテーションコメントタグ
        """
        self.workspace_root = workspace_root
        self.annotation_tag = annotation_tag

    def extract_all(self) -> List[KnowledgeEntity]:
        """
        ワークスペース全体からすべてのアノテーションコメントを抽出
        Returns:
            List[Dict[str, any]]: 抽出されたすべてのコメント
        """
        all_knowledge = []

        for root, dirs, files in os.walk(self.workspace_root):
            root_path = Path(root)

            # 除外ディレクトリをスキップ
            dirs[:] = [d for d in dirs if not self._should_exclude_dir(root_path / d)]

            for file in files:
                file_path = root_path / file

                # 検索対象のファイル以外はスキップ
                if not self._should_include_file(file_path):
                    continue

                # ファイルからコメントを抽出
                knowledge_list = self._extract_knowledge_from_file(file_path)
                all_knowledge.extend(knowledge_list)

        return all_knowledge

    def search(self, search_phrase: str) -> List[KnowledgeEntity]:
        """
        検索語でコメントを検索
        Args:
            search_phrase (str): 検索フレーズ
        Returns:
            List[Dict[str, any]]: 検索にマッチしたコメント
        """
        filtered_knowledge = []
        search_term_lower = search_phrase.lower()
        all_knowledge = self.extract_all()

        for knowledge in all_knowledge:
            # キーワードが含まれていない場合はスキップ（大文字小文字は区別しない）
            content_lower = knowledge.content.lower()
            if search_term_lower not in content_lower:
                continue
            filtered_knowledge.append(knowledge)

        return filtered_knowledge

    def _should_exclude_dir(self, dir_path: Path) -> bool:
        """
        ディレクトリを除外すべきかどうかを判定
        Args:
            dir_path (Path): 判定対象のディレクトリパス
        Returns:
            bool: 除外すべきならTrue
        """
        return dir_path.name in TextSearchConfig.EXCLUDED_DIRS

    def _should_include_file(self, file_path: Path) -> bool:
        """
        ファイルを検索対象に含めるべきかどうかを判定
        Args:
            file_path (Path): 判定対象のファイルパス
        Returns:
            bool: 含めるべきならTrue
        """
        if file_path.suffix == "":
            return file_path.name.lower() in TextSearchConfig.TARGET_NO_EXTENSION_FILES
        return file_path.suffix.lower() in TextSearchConfig.TARGET_EXTENSIONS

    def _is_comment_line(self, line: str) -> bool:
        """
        指定された行がコメント行かどうかを判定
        Args:
            line (str): 判定対象の行
        Returns:
            bool: コメント行の場合True
        """
        stripped_line = line.strip()
        if not stripped_line:
            return False
        for pattern in TextSearchConfig.COMMENT_PATTERNS:
            if re.match(pattern, stripped_line):
                return True
        return False

    def _remove_comment_symbols(self, line: str) -> str:
        """
        行からコメント記号を除去
        Args:
            line (str): コメント記号を含む行
        Returns:
            str: コメント記号を除去した内容
        """
        content = line
        for pattern in TextSearchConfig.COMMENT_PATTERNS:
            content = re.sub(pattern, "", content)
        return content.strip()

    def _is_annotation_line(self, line: str) -> bool:
        """
        指定された行にアノテーションコメントタグが含まれているかを判定
        Args:
            line (str): 判定対象の行
        Returns:
            bool: アノテーションコメントのタグが含まれている場合True
        """
        if self.annotation_tag not in line:
            return False
        # コメント記号を除去してからタグの存在確認
        content = self._remove_comment_symbols(line.strip())
        return self.annotation_tag in content

    def _extract_continuous_comment_lines(
        self, lines: List[str], start_index: int
    ) -> Tuple[List[str], int]:
        """
        指定されたインデックスから連続するコメント行を抽出
        Args:
            lines (List[str]): ファイルの全行
            start_index (int): 開始インデックス
        Returns:
            tuple[List[str], int]: (連続するコメント行のリスト, 次の処理インデックス)
        """
        continuous_lines = []
        j = start_index

        while j < len(lines):
            current_line = lines[j]

            # 空行はスキップして次の行をチェック
            if not current_line.strip():
                j += 1
                continue

            # コメント行でない場合は終了
            if not self._is_comment_line(current_line):
                break

            continuous_lines.append(current_line.strip())
            j += 1

        return continuous_lines, j

    def _create_knowledge_entity(
        self, file_path: Path, line_number: int, continuous_lines: List[str]
    ) -> KnowledgeEntity:
        """
        ナレッジエンティティを作成
        Args:
            file_path (Path): ファイルパス
            line_number (int): 開始行番号
            continuous_lines (List[str]): 連続するコメント行
        Returns:
            KnowledgeEntity: ナレッジエンティティ
        """
        # 全体のコンテンツを結合（コメント記号を除去）
        content_lines = []
        for comment_line in continuous_lines:
            content = self._remove_comment_symbols(comment_line)
            # 空行でない場合のみ追加
            if content:
                content_lines.append(content)
        full_content = "\n".join(content_lines)

        return KnowledgeEntity(
            file_path=str(file_path.relative_to(self.workspace_root)),
            line_number=line_number,
            content=full_content,
            full_line=" ".join(continuous_lines),
            file_extension=file_path.suffix,
        )

    def _extract_knowledge_from_file(self, file_path: Path) -> List[KnowledgeEntity]:
        """
        単一ファイルから対象のコメントを抽出
        Args:
            file_path (Path): 対象ファイルのパス
        Returns:
            List[Dict[str, any]]: 抽出されたコメントのリスト
        """
        knowledge_list = []

        try:
            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                lines = f.readlines()

            i = 0
            while i < len(lines):
                line = lines[i]
                line_num = i + 1

                # アノテーションコメントタグが含まれていない行はスキップ
                if not self._is_annotation_line(line):
                    i += 1
                    continue

                # アノテーションコメントの先頭行から連続するコメント行を抽出
                continuous_lines, next_index = self._extract_continuous_comment_lines(
                    lines, i
                )

                # コメント行がある場合のみナレッジエンティティを作成
                if continuous_lines:
                    knowledge_entity = self._create_knowledge_entity(
                        file_path, line_num, continuous_lines
                    )
                    knowledge_list.append(knowledge_entity)

                # 次の処理のためにインデックスを更新（最低でも1つは進める）
                i = max(next_index, i + 1)

        except Exception as e:
            # ファイル読み込みエラーは無視（バイナリファイル等）
            pass

        return knowledge_list
